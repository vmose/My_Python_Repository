{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9143c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the system is based on one data set and I wanted a system that does clustering\n",
    "#I extracted a dataset with items and customers from the main task file \n",
    "#to run this make sure jupyter notebook/jupyter lab settings in EDIT is running on GPU\n",
    "    #The files were extracted by using pgadmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce292c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "import pandas as pd\n",
    "task_file = pd.read_csv(r'c:\\Output\\task_file.csv')\n",
    "items_df = pd.read_csv(r'c:\\Output\\Items.csv')\n",
    "customers_df = pd.read_csv(r'c:\\Output\\Customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a311d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.read_csv(r'c:\\Output\\Items.csv')\n",
    "customers_df = pd.read_csv(r'c:\\Output\\Customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889f5571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of items dataframe are: (8634, 3) \n",
      "The dimensions of customers dataframe are: (200000, 4)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of items dataframe are:', items_df.shape,'\\nThe dimensions of customers dataframe are:', customers_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee452c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_global_item_id</th>\n",
       "      <th>count</th>\n",
       "      <th>d_item_group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7748</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14837</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10020</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3251</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_global_item_id  count  d_item_group_id\n",
       "0              7748     34                0\n",
       "1            108875      2                0\n",
       "2             14837      2                0\n",
       "3             10020     30                0\n",
       "4              3251      4                0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at items_df\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ef0176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_person_id</th>\n",
       "      <th>d_global_item_id</th>\n",
       "      <th>sales_amount</th>\n",
       "      <th>d_date_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8320</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.707071</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1113</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3336</td>\n",
       "      <td>3.535354</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11707</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_person_id  d_global_item_id  sales_amount   d_date_id\n",
       "0            1              8320      0.505051  2014-09-01\n",
       "1            1                 1      1.707071  2014-09-01\n",
       "2            1              1113      2.727273  2014-09-01\n",
       "3            1              3336      3.535354  2014-09-01\n",
       "4            1             11707      0.959596  2014-09-01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at customers_df\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a92959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 21\n",
      "Number of unique items: 8634\n",
      "The full recommendation matrix will have: 181314 elements.\n",
      "----------\n",
      "Number of transactions: 100000.0\n",
      "Therefore:  55.15293910012464 % of the matrix is filled.\n",
      "We have an incredibly sparse matrix to work with here.\n",
      "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
      "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
      "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
     ]
    }
   ],
   "source": [
    "# items ID to customer mapping\n",
    "items_names = items_df.set_index('d_global_item_id')['count'].to_dict()\n",
    "n_users = len(customers_df.d_person_id.unique())\n",
    "n_items = len(customers_df.d_global_item_id.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique items:\", n_items)\n",
    "print(\"The full recommendation matrix will have:\", n_users*n_items, 'elements.')\n",
    "print('----------')\n",
    "print(\"Number of transactions:\", (len(customers_df))/2)\n",
    "print(\"Therefore: \", (len(customers_df)/2) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
    "print(\"We have an incredibly sparse matrix to work with here.\")\n",
    "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
    "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
    "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d689a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # create user embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
    "        # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        users, items = data[:,0], data[:,1]\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "    # def forward(self, user, item):\n",
    "    # \t# matrix multiplication\n",
    "    #     return (self.user_factors(user)*self.item_factors(item)).sum(1)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39db6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloader (necessary for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.customers = customers_df.copy()\n",
    "        \n",
    "        # Extract all user IDs and item IDs\n",
    "        users = customers_df.d_global_item_id.unique()\n",
    "        items = customers_df.d_person_id.unique()\n",
    "        \n",
    "        #--- Producing new continuous IDs for users and items ---\n",
    "        \n",
    "        # Unique values : index\n",
    "        self.d_person_id2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.d_global_item_id2idx = {o:i for i,o in enumerate(items)}\n",
    "        \n",
    "        # Obtained continuous ID for users and items\n",
    "        self.idx2d_person_id = {i:o for o,i in self.d_person_id2idx.items()}\n",
    "        self.idx2d_global_item_id = {i:o for o,i in self.d_global_item_id2idx.items()}\n",
    "        \n",
    "        # return the id from the indexed values as noted in the lambda function down below.\n",
    "        self.sales_amounts.d_global_item_id = customers_df.d_global_item_id.apply(lambda x: self.d_global_item_id2idx[x])\n",
    "        self.sales_amounts.d_person_id = customers_df.d_person_id.apply(lambda x: self.d_person_id2idx[x])\n",
    "        \n",
    "        \n",
    "        self.x = self.ratings.drop(['sales_amount', 'd_date_id'], axis=1).values\n",
    "        self.y = self.ratings['sales_amount'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sales_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7bf440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(21, 8)\n",
      "  (item_factors): Embedding(8634, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0238, 0.0101, 0.0212, 0.0135, 0.0093, 0.0362, 0.0274, 0.0292],\n",
      "        [0.0423, 0.0039, 0.0221, 0.0090, 0.0452, 0.0236, 0.0330, 0.0085],\n",
      "        [0.0262, 0.0104, 0.0357, 0.0398, 0.0314, 0.0295, 0.0113, 0.0360],\n",
      "        [0.0393, 0.0010, 0.0049, 0.0147, 0.0114, 0.0441, 0.0274, 0.0110],\n",
      "        [0.0370, 0.0392, 0.0070, 0.0118, 0.0020, 0.0143, 0.0230, 0.0357],\n",
      "        [0.0456, 0.0456, 0.0263, 0.0332, 0.0364, 0.0494, 0.0301, 0.0234],\n",
      "        [0.0222, 0.0053, 0.0127, 0.0095, 0.0184, 0.0112, 0.0037, 0.0311],\n",
      "        [0.0415, 0.0462, 0.0472, 0.0124, 0.0229, 0.0332, 0.0447, 0.0372],\n",
      "        [0.0371, 0.0109, 0.0312, 0.0452, 0.0084, 0.0271, 0.0413, 0.0142],\n",
      "        [0.0115, 0.0377, 0.0214, 0.0043, 0.0275, 0.0275, 0.0019, 0.0358],\n",
      "        [0.0327, 0.0405, 0.0027, 0.0116, 0.0325, 0.0240, 0.0131, 0.0243],\n",
      "        [0.0365, 0.0422, 0.0009, 0.0412, 0.0415, 0.0237, 0.0037, 0.0228],\n",
      "        [0.0327, 0.0469, 0.0066, 0.0144, 0.0415, 0.0214, 0.0249, 0.0051],\n",
      "        [0.0275, 0.0256, 0.0009, 0.0470, 0.0169, 0.0239, 0.0144, 0.0327],\n",
      "        [0.0213, 0.0074, 0.0125, 0.0354, 0.0062, 0.0332, 0.0236, 0.0466],\n",
      "        [0.0103, 0.0431, 0.0402, 0.0103, 0.0451, 0.0340, 0.0056, 0.0462],\n",
      "        [0.0116, 0.0107, 0.0129, 0.0048, 0.0119, 0.0017, 0.0464, 0.0420],\n",
      "        [0.0219, 0.0053, 0.0346, 0.0495, 0.0307, 0.0347, 0.0090, 0.0026],\n",
      "        [0.0071, 0.0311, 0.0423, 0.0379, 0.0488, 0.0111, 0.0292, 0.0403],\n",
      "        [0.0088, 0.0345, 0.0261, 0.0154, 0.0418, 0.0127, 0.0348, 0.0296],\n",
      "        [0.0262, 0.0425, 0.0064, 0.0089, 0.0150, 0.0034, 0.0135, 0.0290]])\n",
      "item_factors.weight tensor([[0.0062, 0.0284, 0.0284,  ..., 0.0251, 0.0241, 0.0311],\n",
      "        [0.0483, 0.0393, 0.0390,  ..., 0.0054, 0.0310, 0.0086],\n",
      "        [0.0419, 0.0198, 0.0189,  ..., 0.0322, 0.0209, 0.0113],\n",
      "        ...,\n",
      "        [0.0032, 0.0327, 0.0287,  ..., 0.0331, 0.0419, 0.0087],\n",
      "        [0.0450, 0.0448, 0.0207,  ..., 0.0367, 0.0301, 0.0335],\n",
      "        [0.0104, 0.0035, 0.0036,  ..., 0.0071, 0.0357, 0.0323]])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "8320",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f096354fb4b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-06671f1dc23d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# return the id from the indexed values as noted in the lambda function down below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msales_amounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_global_item_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_global_item_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_global_item_id2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msales_amounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_person_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_person_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_person_id2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-06671f1dc23d>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# return the id from the indexed values as noted in the lambda function down below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msales_amounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_global_item_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_global_item_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_global_item_id2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msales_amounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_person_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_person_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_person_id2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 8320"
     ]
    }
   ],
   "source": [
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e9d749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-dad152416852>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for it in tqdm(range(num_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0327c55ae343a88c9a6c93679c745a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dad152416852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m          \u001b[1;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "         if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18aead44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[0.0238, 0.0101, 0.0212, 0.0135, 0.0093, 0.0362, 0.0274, 0.0292],\n",
      "        [0.0423, 0.0039, 0.0221, 0.0090, 0.0452, 0.0236, 0.0330, 0.0085],\n",
      "        [0.0262, 0.0104, 0.0357, 0.0398, 0.0314, 0.0295, 0.0113, 0.0360],\n",
      "        [0.0393, 0.0010, 0.0049, 0.0147, 0.0114, 0.0441, 0.0274, 0.0110],\n",
      "        [0.0370, 0.0392, 0.0070, 0.0118, 0.0020, 0.0143, 0.0230, 0.0357],\n",
      "        [0.0456, 0.0456, 0.0263, 0.0332, 0.0364, 0.0494, 0.0301, 0.0234],\n",
      "        [0.0222, 0.0053, 0.0127, 0.0095, 0.0184, 0.0112, 0.0037, 0.0311],\n",
      "        [0.0415, 0.0462, 0.0472, 0.0124, 0.0229, 0.0332, 0.0447, 0.0372],\n",
      "        [0.0371, 0.0109, 0.0312, 0.0452, 0.0084, 0.0271, 0.0413, 0.0142],\n",
      "        [0.0115, 0.0377, 0.0214, 0.0043, 0.0275, 0.0275, 0.0019, 0.0358],\n",
      "        [0.0327, 0.0405, 0.0027, 0.0116, 0.0325, 0.0240, 0.0131, 0.0243],\n",
      "        [0.0365, 0.0422, 0.0009, 0.0412, 0.0415, 0.0237, 0.0037, 0.0228],\n",
      "        [0.0327, 0.0469, 0.0066, 0.0144, 0.0415, 0.0214, 0.0249, 0.0051],\n",
      "        [0.0275, 0.0256, 0.0009, 0.0470, 0.0169, 0.0239, 0.0144, 0.0327],\n",
      "        [0.0213, 0.0074, 0.0125, 0.0354, 0.0062, 0.0332, 0.0236, 0.0466],\n",
      "        [0.0103, 0.0431, 0.0402, 0.0103, 0.0451, 0.0340, 0.0056, 0.0462],\n",
      "        [0.0116, 0.0107, 0.0129, 0.0048, 0.0119, 0.0017, 0.0464, 0.0420],\n",
      "        [0.0219, 0.0053, 0.0346, 0.0495, 0.0307, 0.0347, 0.0090, 0.0026],\n",
      "        [0.0071, 0.0311, 0.0423, 0.0379, 0.0488, 0.0111, 0.0292, 0.0403],\n",
      "        [0.0088, 0.0345, 0.0261, 0.0154, 0.0418, 0.0127, 0.0348, 0.0296],\n",
      "        [0.0262, 0.0425, 0.0064, 0.0089, 0.0150, 0.0034, 0.0135, 0.0290]])\n",
      "item_factors.weight tensor([[0.0062, 0.0284, 0.0284,  ..., 0.0251, 0.0241, 0.0311],\n",
      "        [0.0483, 0.0393, 0.0390,  ..., 0.0054, 0.0310, 0.0086],\n",
      "        [0.0419, 0.0198, 0.0189,  ..., 0.0322, 0.0209, 0.0113],\n",
      "        ...,\n",
      "        [0.0032, 0.0327, 0.0287,  ..., 0.0331, 0.0419, 0.0087],\n",
      "        [0.0450, 0.0448, 0.0207,  ..., 0.0367, 0.0301, 0.0335],\n",
      "        [0.0104, 0.0035, 0.0036,  ..., 0.0071, 0.0357, 0.0323]])\n"
     ]
    }
   ],
   "source": [
    "# By training the model, we will have tuned latent factors for items and users.\n",
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "          uw = param.data\n",
    "          c +=1\n",
    "        else:\n",
    "          iw = param.data\n",
    "        #print('param_data', param_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2750b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_item_embeddings = model.item_factors.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e37398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8634"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_item_embeddings) # unique item factor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3cccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb8c8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-78b25c2f7ea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0md_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0md_itemsidx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0md_itemsid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx2d_global_item_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_itemsidx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0msales_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcustomers_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'd_global_item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0md_itemsid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0md_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_itemsid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msales_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "'''It can be seen here that the items that are in the same cluster tend to be of\n",
    "similar item groups. Also note the algorithm only obtained the relationships by looking at the numbers representing how\n",
    "users have responded to the item selections.'''\n",
    "for cluster in range(10):\n",
    "  print(\"Cluster #{}\".format(cluster))\n",
    "  d_items = []\n",
    "  for d_itemsidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "    d_itemsid = train_set.idx2d_global_item_id[d_itemsidx]\n",
    "    sales_count = customers_df.loc[customers_df['d_global_item_id']==d_itemsid].count()[0]\n",
    "    d_items.append((user_names[d_itemsid], sales_count))\n",
    "  for d_items in sorted(d_items, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "    print(\"\\t\", d_items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1afc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
